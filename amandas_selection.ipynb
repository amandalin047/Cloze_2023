{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0785c43f-a31a-46fc-8395-6090355b887d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def REINDEX(array):\n",
    "    '''Sorts sentences by a given index in asencing order'''\n",
    "    array_ascend = np.sort(array)\n",
    "    unique, idx = [], []\n",
    "    for i, x in enumerate(array_ascend):\n",
    "        if x not in unique:\n",
    "            idx.append(np.where(array==x)[0].tolist())\n",
    "            unique.append(x)\n",
    "    return sum(idx, [])\n",
    "\n",
    "def main(df1, df2, exp_thresh=4.5, plaus_thresh=5, val_thresh=2, condition=None, disp=True, drop=True):\n",
    "    df = pd.concat((df1, df2)).reset_index(drop=True);\n",
    "    df = df.reindex(REINDEX(df['cloze(unexp_uncorrected)'])).reset_index(drop=True);\n",
    "    \n",
    "    num_zero_cloze = len([i for i in df['cloze(unexp_uncorrected)'].tolist() if i==0])\n",
    "    new_df = pd.DataFrame(None, columns=df.columns)\n",
    "    for i in range(len(df.head(num_zero_cloze))):\n",
    "        if df['exp_mean'].iloc[i] <= exp_thresh: new_df.loc[len(new_df)] = df.iloc[i]     \n",
    "\n",
    "    for i in range(len(df.head(num_zero_cloze)),len(df)):\n",
    "        if df['Index'].iloc[i] in new_df['Index'].tolist(): new_df.loc[len(new_df)] = df.iloc[i]\n",
    "    \n",
    "    new_df = new_df.reindex(REINDEX(new_df['Index'])).reset_index(drop=True)\n",
    "    \n",
    "    new_df = new_df[new_df['plaus_mean']>=plaus_thresh]\n",
    "    if condition == 'Emo':\n",
    "        new_df = new_df[(new_df['S_val_mean']>=5+val_thresh) | (new_df['S_val_mean']<=5-val_thresh)].reset_index(drop=True)\n",
    "    elif condition == 'Neu':\n",
    "        new_df = new_df[(new_df['S_val_mean']<=5+val_thresh) & (new_df['S_val_mean']>=5-val_thresh)].reset_index(drop=True)\n",
    "    new_df = new_df.reindex(REINDEX(new_df['Index'])).reset_index(drop=True)\n",
    "    \n",
    "    # drops sentences that do not have a counterpart\n",
    "    if drop == True:\n",
    "        idx = new_df['Index'].tolist()\n",
    "        for i, x in enumerate(idx):\n",
    "            if idx.count(x) == 1:\n",
    "                new_df = new_df.drop(index=i)\n",
    "                \n",
    "    if drop == True:\n",
    "        sc, wc = new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)], new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)]\n",
    "        print('number of '+condition+'_SC frames (i.e., with counterparts) =', int(len(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)])/2))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)])\n",
    "        print('number of '+condition+'_WC frames (i.e., with counterparts) =', int(len(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)])/2))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)])\n",
    "    else:\n",
    "        sc, wc = new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)], new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)]\n",
    "        print('number of '+condition+'_SC sentences =', len(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)]))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)])\n",
    "        print('number of '+condition+'_WC sentences =', len(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)]))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)])  \n",
    "    \n",
    "    return sc, wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49a3f78-68d4-45c5-b04b-08bd70e88e04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Emo_SC frames (i.e., with counterparts) = 82\n",
      "number of Emo_WC frames (i.e., with counterparts) = 85\n",
      "number of Neu_SC frames (i.e., with counterparts) = 77\n",
      "number of Neu_WC frames (i.e., with counterparts) = 76\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/mnt/c/Users/amand/Downloads/ratings_072323')\n",
    "df1 = pd.read_excel('master_sheet_v3-1(2023.07.19_1st_round)_updated.xlsx', sheet_name='master_sheet').tail(487)\n",
    "df2 = pd.read_excel('master_sheet_v3-2(2023.07.19_2nd_round).xlsx', sheet_name='master_sheet')\n",
    "\n",
    "emo_sc, emo_wc = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=1.6, condition='Emo', disp=False, drop=True);\n",
    "neu_sc, neu_wc = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=0.9, condition='Neu', disp=False, drop=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef76474-e688-4f03-93eb-1c2384e80396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Emo_SC sentences = 177\n",
      "number of Emo_WC sentences = 187\n",
      "number of Neu_SC sentences = 163\n",
      "number of Neu_WC sentences = 163\n",
      "\n",
      "\n",
      "number of singled out Emo_SC sentences (i.e., with no counterpart) = 13\n",
      "number of singled out Emo_WC sentences (i.e., with no counterpart) = 17\n",
      "number of singled out Neu_SC sentences (i.e., with no counterpart) = 9\n",
      "number of singled out Neu_WC sentences (i.e., with no counterpart) = 11\n"
     ]
    }
   ],
   "source": [
    "emo_sc_toSubset, emo_wc_toSubset = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=1.6, condition='Emo', disp=False, drop=False);\n",
    "neu_sc_toSubset, neu_wc_toSubset = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=0.9, condition='Neu', disp=False, drop=False);\n",
    "\n",
    "toSubset = [emo_sc_toSubset, emo_wc_toSubset, neu_sc_toSubset, neu_wc_toSubset]\n",
    "subsetted = []\n",
    "for f in toSubset:\n",
    "    new_df = pd.DataFrame(None, columns=f.columns)\n",
    "    idx = f['Index'].tolist()\n",
    "    for i, x in enumerate(idx):\n",
    "        if idx.count(x) == 1: new_df.loc[len(new_df)] = f.iloc[i]\n",
    "    subsetted.append(new_df)\n",
    "print('\\n')    \n",
    "to_print = ['number of singled out Emo_SC sentences (i.e., with no counterpart) = ', 'number of singled out Emo_WC sentences (i.e., with no counterpart) = ',\n",
    "            'number of singled out Neu_SC sentences (i.e., with no counterpart) = ', 'number of singled out Neu_WC sentences (i.e., with no counterpart) = ']\n",
    "for i, x in enumerate(subsetted):\n",
    "    print(to_print[i] + str(len(x.index)))\n",
    "    \n",
    "disp, to_excel = False, False\n",
    "if disp == True: dsipaly(x)\n",
    "if to_excel == True: x.to_excel('/home/amandalin047/july_ratings/'+to_print[i]+'.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
