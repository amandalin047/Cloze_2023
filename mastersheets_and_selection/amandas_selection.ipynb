{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d06e70-e113-4ac6-9fee-8ac800a622e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4acb05a-2bed-4bf1-99b0-1622d0d99cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def REINDEX(array):\n",
    "    '''Sorts sentences by a given index in asencing order'''\n",
    "    array_ascend = np.sort(array)\n",
    "    unique, idx = [], []\n",
    "    for i, x in enumerate(array_ascend):\n",
    "        if x not in unique:\n",
    "            idx.append(np.where(array==x)[0].tolist())\n",
    "            unique.append(x)\n",
    "    return sum(idx, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f7d3e0-2934-4fa5-a784-04927fdfd883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Origin_condition</th>\n",
       "      <th>Whole_S</th>\n",
       "      <th>Sframes</th>\n",
       "      <th>Completions</th>\n",
       "      <th>S_constraint</th>\n",
       "      <th>cloze(unexp_uncorrected)</th>\n",
       "      <th>plaus_mean</th>\n",
       "      <th>plaus_std</th>\n",
       "      <th>exp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>W_val_mean</th>\n",
       "      <th>W_val_std</th>\n",
       "      <th>W_arous_mean</th>\n",
       "      <th>W_arous_std</th>\n",
       "      <th>W_familiarity_mean</th>\n",
       "      <th>W_familiarity_std</th>\n",
       "      <th>W_concreteness_mean</th>\n",
       "      <th>W_concreteness_std</th>\n",
       "      <th>Use-Plaus(0:False/1:True)</th>\n",
       "      <th>Use-S_valence(0:False/1:True)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>Emo_SCU</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人關切</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人</td>\n",
       "      <td>關切</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1.203698</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>1.339447</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.909727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>Emo_SCE</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人同情</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人</td>\n",
       "      <td>同情</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.398412</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>1.459166</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.586401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>Neu_SCU</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護關切</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護</td>\n",
       "      <td>關切</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.514376</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>1.339447</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.909727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>Neu_SCE</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護照顧</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護</td>\n",
       "      <td>照顧</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.832666</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.200490</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>2.600277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>Emo_WCE</td>\n",
       "      <td>男星在臉書放與辣妹親暱的合照，粉絲們說是女友</td>\n",
       "      <td>男星在臉書放與辣妹親暱的合照，粉絲們說是</td>\n",
       "      <td>女友</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1.499630</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>2.015564</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1405</td>\n",
       "      <td>Neu_SCE</td>\n",
       "      <td>小華明天要考英文，難怪他今天這麼認真在背單字</td>\n",
       "      <td>小華明天要考英文，難怪他今天這麼認真在背</td>\n",
       "      <td>單字</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.764706</td>\n",
       "      <td>0.424183</td>\n",
       "      <td>6.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.407463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1416</td>\n",
       "      <td>Emo_SCE</td>\n",
       "      <td>報告時教授不斷點頭稱讚，顯然對研究成果非常滿意</td>\n",
       "      <td>報告時教授不斷點頭稱讚，顯然對研究成果非常</td>\n",
       "      <td>滿意</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>6.764706</td>\n",
       "      <td>0.424183</td>\n",
       "      <td>6.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>1.087811</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.851801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1416</td>\n",
       "      <td>Emo_SCU</td>\n",
       "      <td>報告時教授不斷點頭稱讚，顯然對研究成果非常賞識</td>\n",
       "      <td>報告時教授不斷點頭稱讚，顯然對研究成果非常</td>\n",
       "      <td>賞識</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>0.499134</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>1.024695</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>2.421260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1424</td>\n",
       "      <td>Emo_SCU</td>\n",
       "      <td>伴侶送我手寫的暖心卡片，是我收過最有意義的手作</td>\n",
       "      <td>伴侶送我手寫的暖心卡片，是我收過最有意義的</td>\n",
       "      <td>手作</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.823529</td>\n",
       "      <td>1.423967</td>\n",
       "      <td>4.470588</td>\n",
       "      <td>...</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>0.351866</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.016598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1424</td>\n",
       "      <td>Emo_SCE</td>\n",
       "      <td>伴侶送我手寫的暖心卡片，是我收過最有意義的禮物</td>\n",
       "      <td>伴侶送我手寫的暖心卡片，是我收過最有意義的</td>\n",
       "      <td>禮物</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>6.647059</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.253566</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>2.028370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index Origin_condition                  Whole_S                Sframes  \\\n",
       "80       0          Emo_SCU     有些人常怨天尤人自怨自艾，以博取他人關切     有些人常怨天尤人自怨自艾，以博取他人   \n",
       "81       0          Emo_SCE     有些人常怨天尤人自怨自艾，以博取他人同情     有些人常怨天尤人自怨自艾，以博取他人   \n",
       "82       1          Neu_SCU      阿公已無法自理生活，因此想要被看護關切      阿公已無法自理生活，因此想要被看護   \n",
       "83       1          Neu_SCE      阿公已無法自理生活，因此想要被看護照顧      阿公已無法自理生活，因此想要被看護   \n",
       "84       2          Emo_WCE   男星在臉書放與辣妹親暱的合照，粉絲們說是女友   男星在臉書放與辣妹親暱的合照，粉絲們說是   \n",
       "..     ...              ...                      ...                    ...   \n",
       "554   1405          Neu_SCE   小華明天要考英文，難怪他今天這麼認真在背單字   小華明天要考英文，難怪他今天這麼認真在背   \n",
       "555   1416          Emo_SCE  報告時教授不斷點頭稱讚，顯然對研究成果非常滿意  報告時教授不斷點頭稱讚，顯然對研究成果非常   \n",
       "556   1416          Emo_SCU  報告時教授不斷點頭稱讚，顯然對研究成果非常賞識  報告時教授不斷點頭稱讚，顯然對研究成果非常   \n",
       "557   1424          Emo_SCU  伴侶送我手寫的暖心卡片，是我收過最有意義的手作  伴侶送我手寫的暖心卡片，是我收過最有意義的   \n",
       "558   1424          Emo_SCE  伴侶送我手寫的暖心卡片，是我收過最有意義的禮物  伴侶送我手寫的暖心卡片，是我收過最有意義的   \n",
       "\n",
       "    Completions  S_constraint  cloze(unexp_uncorrected)  plaus_mean  \\\n",
       "80           關切      0.866667                  0.000000    5.533333   \n",
       "81           同情      0.866667                  0.866667    5.666667   \n",
       "82           關切      1.000000                  0.000000    2.800000   \n",
       "83           照顧      1.000000                  1.000000    6.200000   \n",
       "84           女友      0.066667                  0.066667    5.533333   \n",
       "..          ...           ...                       ...         ...   \n",
       "554          單字      1.000000                  1.000000    6.764706   \n",
       "555          滿意      0.950000                  0.950000    6.764706   \n",
       "556          賞識      0.950000                  0.000000    6.470588   \n",
       "557          手作      0.866667                  0.000000    5.823529   \n",
       "558          禮物      0.866667                  0.866667    6.647059   \n",
       "\n",
       "     plaus_std  exp_mean  ...  W_val_mean  W_val_std  W_arous_mean  \\\n",
       "80    1.203698  4.933333  ...    5.166667   1.339447      3.333333   \n",
       "81    1.398412  4.733333  ...    5.437500   1.459166      3.375000   \n",
       "82    1.514376  2.466667  ...    5.166667   1.339447      3.333333   \n",
       "83    0.832666  5.200000  ...    5.500000   1.200490      2.944444   \n",
       "84    1.499630  5.000000  ...    5.937500   2.015564      3.750000   \n",
       "..         ...       ...  ...         ...        ...           ...   \n",
       "554   0.424183  6.705882  ...    4.933333   0.258199      1.866667   \n",
       "555   0.424183  6.764706  ...    7.125000   1.087811      3.312500   \n",
       "556   0.499134  5.882353  ...    6.875000   1.024695      3.562500   \n",
       "557   1.423967  4.470588  ...    5.133333   0.351866      2.933333   \n",
       "558   0.762440  6.470588  ...    7.000000   1.253566      4.600000   \n",
       "\n",
       "     W_arous_std  W_familiarity_mean  W_familiarity_std  W_concreteness_mean  \\\n",
       "80      1.909727                 NaN                NaN                  NaN   \n",
       "81      1.586401                 NaN                NaN                  NaN   \n",
       "82      1.909727                 NaN                NaN                  NaN   \n",
       "83      2.600277                 NaN                NaN                  NaN   \n",
       "84      3.214550                 NaN                NaN                  NaN   \n",
       "..           ...                 ...                ...                  ...   \n",
       "554     1.407463                 NaN                NaN                  NaN   \n",
       "555     1.851801                 NaN                NaN                  NaN   \n",
       "556     2.421260                 NaN                NaN                  NaN   \n",
       "557     2.016598                 NaN                NaN                  NaN   \n",
       "558     2.028370                 NaN                NaN                  NaN   \n",
       "\n",
       "     W_concreteness_std  Use-Plaus(0:False/1:True)  \\\n",
       "80                  NaN                        1.0   \n",
       "81                  NaN                        1.0   \n",
       "82                  NaN                        0.0   \n",
       "83                  NaN                        1.0   \n",
       "84                  NaN                        1.0   \n",
       "..                  ...                        ...   \n",
       "554                 NaN                        1.0   \n",
       "555                 NaN                        1.0   \n",
       "556                 NaN                        1.0   \n",
       "557                 NaN                        1.0   \n",
       "558                 NaN                        1.0   \n",
       "\n",
       "     Use-S_valence(0:False/1:True)  \n",
       "80                             NaN  \n",
       "81                             NaN  \n",
       "82                             NaN  \n",
       "83                             NaN  \n",
       "84                             NaN  \n",
       "..                             ...  \n",
       "554                            NaN  \n",
       "555                            NaN  \n",
       "556                            NaN  \n",
       "557                            NaN  \n",
       "558                            NaN  \n",
       "\n",
       "[479 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Origin_condition</th>\n",
       "      <th>Whole_S</th>\n",
       "      <th>Sframes</th>\n",
       "      <th>Completions</th>\n",
       "      <th>S_constraint</th>\n",
       "      <th>cloze(unexp_uncorrected)</th>\n",
       "      <th>plaus_mean</th>\n",
       "      <th>plaus_std</th>\n",
       "      <th>exp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>W_val_mean</th>\n",
       "      <th>W_val_std</th>\n",
       "      <th>W_arous_mean</th>\n",
       "      <th>W_arous_std</th>\n",
       "      <th>W_familiarity_mean</th>\n",
       "      <th>W_familiarity_std</th>\n",
       "      <th>W_concreteness_mean</th>\n",
       "      <th>W_concreteness_std</th>\n",
       "      <th>Use-Plaus(0:False/1:True)</th>\n",
       "      <th>Use-S_valence(0:False/1:True)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>Neu_WCE</td>\n",
       "      <td>員工繳交報告後上司要求補充，因為裡面沒有員工的想法</td>\n",
       "      <td>員工繳交報告後上司要求補充，因為裡面沒有員工的</td>\n",
       "      <td>想法</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>0.884433</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>1.543805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>Neu_WCU</td>\n",
       "      <td>員工繳交報告後上司要求補充，因為裡面沒有員工的主張</td>\n",
       "      <td>員工繳交報告後上司要求補充，因為裡面沒有員工的</td>\n",
       "      <td>主張</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.074968</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.556550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>Neu_WCE</td>\n",
       "      <td>他前年把原本老師的工作辭掉，現在轉行當家教</td>\n",
       "      <td>他前年把原本老師的工作辭掉，現在轉行當</td>\n",
       "      <td>家教</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>1.436044</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.944444</td>\n",
       "      <td>1.731107</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>1.406102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>Neu_WCU</td>\n",
       "      <td>他前年把原本老師的工作辭掉，現在轉行當導演</td>\n",
       "      <td>他前年把原本老師的工作辭掉，現在轉行當</td>\n",
       "      <td>導演</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.952190</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.028992</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.016274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>Neu_WCE</td>\n",
       "      <td>等一下臨時演員走到台前時，請你跟他握手</td>\n",
       "      <td>等一下臨時演員走到台前時，請你跟他</td>\n",
       "      <td>握手</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.879394</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>0.985184</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.757338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1986</td>\n",
       "      <td>Emo_WCU</td>\n",
       "      <td>這位工作人員做事十分認真，服務客人的品質很標準</td>\n",
       "      <td>這位工作人員做事十分認真，服務客人的品質很</td>\n",
       "      <td>標準</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.166190</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>0.704154</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.204159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1990</td>\n",
       "      <td>Emo_WCE</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找出路</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找</td>\n",
       "      <td>出路</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>1.203698</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.236694</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.986885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1990</td>\n",
       "      <td>Emo_WCU</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找文獻</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找</td>\n",
       "      <td>文獻</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.966384</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.023669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1998</td>\n",
       "      <td>Emo_WCE</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很無奈</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很</td>\n",
       "      <td>無奈</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>1.024153</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.899735</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.496026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1998</td>\n",
       "      <td>Emo_WCU</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很不意外</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很</td>\n",
       "      <td>不意外</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>1.181336</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.064581</td>\n",
       "      <td>2.687500</td>\n",
       "      <td>1.778342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index Origin_condition                    Whole_S  \\\n",
       "0       55          Neu_WCE  員工繳交報告後上司要求補充，因為裡面沒有員工的想法   \n",
       "1       55          Neu_WCU  員工繳交報告後上司要求補充，因為裡面沒有員工的主張   \n",
       "2       59          Neu_WCE      他前年把原本老師的工作辭掉，現在轉行當家教   \n",
       "3       59          Neu_WCU      他前年把原本老師的工作辭掉，現在轉行當導演   \n",
       "4       63          Neu_WCE        等一下臨時演員走到台前時，請你跟他握手   \n",
       "..     ...              ...                        ...   \n",
       "475   1986          Emo_WCU    這位工作人員做事十分認真，服務客人的品質很標準   \n",
       "476   1990          Emo_WCE   他榮獲傑出教師獎，致力教學外也積極幫學生尋找出路   \n",
       "477   1990          Emo_WCU   他榮獲傑出教師獎，致力教學外也積極幫學生尋找文獻   \n",
       "478   1998          Emo_WCE        大雄已慣於災難性思考，朋友都感到很無奈   \n",
       "479   1998          Emo_WCU       大雄已慣於災難性思考，朋友都感到很不意外   \n",
       "\n",
       "                     Sframes Completions  S_constraint  \\\n",
       "0    員工繳交報告後上司要求補充，因為裡面沒有員工的          想法      0.133333   \n",
       "1    員工繳交報告後上司要求補充，因為裡面沒有員工的          主張      0.133333   \n",
       "2        他前年把原本老師的工作辭掉，現在轉行當          家教      0.133333   \n",
       "3        他前年把原本老師的工作辭掉，現在轉行當          導演      0.133333   \n",
       "4          等一下臨時演員走到台前時，請你跟他          握手      0.133333   \n",
       "..                       ...         ...           ...   \n",
       "475    這位工作人員做事十分認真，服務客人的品質很          標準      0.200000   \n",
       "476   他榮獲傑出教師獎，致力教學外也積極幫學生尋找          出路      0.200000   \n",
       "477   他榮獲傑出教師獎，致力教學外也積極幫學生尋找          文獻      0.200000   \n",
       "478        大雄已慣於災難性思考，朋友都感到很          無奈      0.200000   \n",
       "479        大雄已慣於災難性思考，朋友都感到很         不意外      0.200000   \n",
       "\n",
       "     cloze(unexp_uncorrected)  plaus_mean  plaus_std  exp_mean  ...  \\\n",
       "0                    0.133333    6.133333   0.884433  4.400000  ...   \n",
       "1                    0.000000    5.333333   1.074968  3.933333  ...   \n",
       "2                    0.133333    5.933333   1.436044  5.200000  ...   \n",
       "3                    0.000000    6.400000   0.952190  5.066667  ...   \n",
       "4                    0.133333    6.400000   0.879394  5.066667  ...   \n",
       "..                        ...         ...        ...       ...  ...   \n",
       "475                  0.000000    5.200000   1.166190  3.866667  ...   \n",
       "476                  0.200000    5.866667   1.203698  5.066667  ...   \n",
       "477                  0.000000    5.000000   1.966384  4.333333  ...   \n",
       "478                  0.200000    5.866667   1.024153  5.133333  ...   \n",
       "479                  0.000000    5.933333   1.181336  5.466667  ...   \n",
       "\n",
       "     W_val_mean  W_val_std  W_arous_mean  W_arous_std  W_familiarity_mean  \\\n",
       "0      5.562500   0.892095      2.125000     1.543805                 NaN   \n",
       "1      4.888889   0.471405      2.222222     2.556550                 NaN   \n",
       "2      4.944444   1.731107      2.277778     1.406102                 NaN   \n",
       "3      5.000000   1.028992      2.222222     2.016274                 NaN   \n",
       "4      5.166667   0.985184      2.166667     1.757338                 NaN   \n",
       "..          ...        ...           ...          ...                 ...   \n",
       "475    5.312500   0.704154      1.625000     1.204159                 NaN   \n",
       "476    5.666667   1.236694      2.222222     1.986885                 NaN   \n",
       "477    4.866667   0.516398      2.666667     2.023669                 NaN   \n",
       "478    3.333333   0.899735      3.666667     1.496026                 NaN   \n",
       "479    4.750000   1.064581      2.687500     1.778342                 NaN   \n",
       "\n",
       "     W_familiarity_std  W_concreteness_mean  W_concreteness_std  \\\n",
       "0                  NaN                  NaN                 NaN   \n",
       "1                  NaN                  NaN                 NaN   \n",
       "2                  NaN                  NaN                 NaN   \n",
       "3                  NaN                  NaN                 NaN   \n",
       "4                  NaN                  NaN                 NaN   \n",
       "..                 ...                  ...                 ...   \n",
       "475                NaN                  NaN                 NaN   \n",
       "476                NaN                  NaN                 NaN   \n",
       "477                NaN                  NaN                 NaN   \n",
       "478                NaN                  NaN                 NaN   \n",
       "479                NaN                  NaN                 NaN   \n",
       "\n",
       "     Use-Plaus(0:False/1:True)  Use-S_valence(0:False/1:True)  \n",
       "0                          NaN                            NaN  \n",
       "1                          NaN                            NaN  \n",
       "2                          NaN                            NaN  \n",
       "3                          NaN                            NaN  \n",
       "4                          NaN                            NaN  \n",
       "..                         ...                            ...  \n",
       "475                        NaN                            NaN  \n",
       "476                        NaN                            NaN  \n",
       "477                        NaN                            NaN  \n",
       "478                        NaN                            NaN  \n",
       "479                        NaN                            NaN  \n",
       "\n",
       "[480 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Origin_condition</th>\n",
       "      <th>Whole_S</th>\n",
       "      <th>Sframes</th>\n",
       "      <th>Completions</th>\n",
       "      <th>S_constraint</th>\n",
       "      <th>cloze(unexp_uncorrected)</th>\n",
       "      <th>plaus_mean</th>\n",
       "      <th>plaus_std</th>\n",
       "      <th>exp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>W_val_mean</th>\n",
       "      <th>W_val_std</th>\n",
       "      <th>W_arous_mean</th>\n",
       "      <th>W_arous_std</th>\n",
       "      <th>W_familiarity_mean</th>\n",
       "      <th>W_familiarity_std</th>\n",
       "      <th>W_concreteness_mean</th>\n",
       "      <th>W_concreteness_std</th>\n",
       "      <th>Use-Plaus(0:False/1:True)</th>\n",
       "      <th>Use-S_valence(0:False/1:True)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Emo_SCU</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人關切</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人</td>\n",
       "      <td>關切</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1.203698</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>1.339447</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.909727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Emo_SCE</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人同情</td>\n",
       "      <td>有些人常怨天尤人自怨自艾，以博取他人</td>\n",
       "      <td>同情</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.398412</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>1.459166</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>1.586401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Neu_SCU</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護關切</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護</td>\n",
       "      <td>關切</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.514376</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>1.339447</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.909727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Neu_SCE</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護照顧</td>\n",
       "      <td>阿公已無法自理生活，因此想要被看護</td>\n",
       "      <td>照顧</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.832666</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.200490</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>2.600277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Emo_WCE</td>\n",
       "      <td>男星在臉書放與辣妹親暱的合照，粉絲們說是女友</td>\n",
       "      <td>男星在臉書放與辣妹親暱的合照，粉絲們說是</td>\n",
       "      <td>女友</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1.499630</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>2.015564</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1986</td>\n",
       "      <td>Emo_WCU</td>\n",
       "      <td>這位工作人員做事十分認真，服務客人的品質很標準</td>\n",
       "      <td>這位工作人員做事十分認真，服務客人的品質很</td>\n",
       "      <td>標準</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.166190</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>0.704154</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.204159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1990</td>\n",
       "      <td>Emo_WCE</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找出路</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找</td>\n",
       "      <td>出路</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>1.203698</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.236694</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.986885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1990</td>\n",
       "      <td>Emo_WCU</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找文獻</td>\n",
       "      <td>他榮獲傑出教師獎，致力教學外也積極幫學生尋找</td>\n",
       "      <td>文獻</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.966384</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.023669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1998</td>\n",
       "      <td>Emo_WCE</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很無奈</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很</td>\n",
       "      <td>無奈</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>1.024153</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.899735</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.496026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>1998</td>\n",
       "      <td>Emo_WCU</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很不意外</td>\n",
       "      <td>大雄已慣於災難性思考，朋友都感到很</td>\n",
       "      <td>不意外</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>1.181336</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.064581</td>\n",
       "      <td>2.687500</td>\n",
       "      <td>1.778342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index Origin_condition                   Whole_S                 Sframes  \\\n",
       "0        0          Emo_SCU      有些人常怨天尤人自怨自艾，以博取他人關切      有些人常怨天尤人自怨自艾，以博取他人   \n",
       "1        0          Emo_SCE      有些人常怨天尤人自怨自艾，以博取他人同情      有些人常怨天尤人自怨自艾，以博取他人   \n",
       "2        1          Neu_SCU       阿公已無法自理生活，因此想要被看護關切       阿公已無法自理生活，因此想要被看護   \n",
       "3        1          Neu_SCE       阿公已無法自理生活，因此想要被看護照顧       阿公已無法自理生活，因此想要被看護   \n",
       "4        2          Emo_WCE    男星在臉書放與辣妹親暱的合照，粉絲們說是女友    男星在臉書放與辣妹親暱的合照，粉絲們說是   \n",
       "..     ...              ...                       ...                     ...   \n",
       "954   1986          Emo_WCU   這位工作人員做事十分認真，服務客人的品質很標準   這位工作人員做事十分認真，服務客人的品質很   \n",
       "955   1990          Emo_WCE  他榮獲傑出教師獎，致力教學外也積極幫學生尋找出路  他榮獲傑出教師獎，致力教學外也積極幫學生尋找   \n",
       "956   1990          Emo_WCU  他榮獲傑出教師獎，致力教學外也積極幫學生尋找文獻  他榮獲傑出教師獎，致力教學外也積極幫學生尋找   \n",
       "957   1998          Emo_WCE       大雄已慣於災難性思考，朋友都感到很無奈       大雄已慣於災難性思考，朋友都感到很   \n",
       "958   1998          Emo_WCU      大雄已慣於災難性思考，朋友都感到很不意外       大雄已慣於災難性思考，朋友都感到很   \n",
       "\n",
       "    Completions  S_constraint  cloze(unexp_uncorrected)  plaus_mean  \\\n",
       "0            關切      0.866667                  0.000000    5.533333   \n",
       "1            同情      0.866667                  0.866667    5.666667   \n",
       "2            關切      1.000000                  0.000000    2.800000   \n",
       "3            照顧      1.000000                  1.000000    6.200000   \n",
       "4            女友      0.066667                  0.066667    5.533333   \n",
       "..          ...           ...                       ...         ...   \n",
       "954          標準      0.200000                  0.000000    5.200000   \n",
       "955          出路      0.200000                  0.200000    5.866667   \n",
       "956          文獻      0.200000                  0.000000    5.000000   \n",
       "957          無奈      0.200000                  0.200000    5.866667   \n",
       "958         不意外      0.200000                  0.000000    5.933333   \n",
       "\n",
       "     plaus_std  exp_mean  ...  W_val_mean  W_val_std  W_arous_mean  \\\n",
       "0     1.203698  4.933333  ...    5.166667   1.339447      3.333333   \n",
       "1     1.398412  4.733333  ...    5.437500   1.459166      3.375000   \n",
       "2     1.514376  2.466667  ...    5.166667   1.339447      3.333333   \n",
       "3     0.832666  5.200000  ...    5.500000   1.200490      2.944444   \n",
       "4     1.499630  5.000000  ...    5.937500   2.015564      3.750000   \n",
       "..         ...       ...  ...         ...        ...           ...   \n",
       "954   1.166190  3.866667  ...    5.312500   0.704154      1.625000   \n",
       "955   1.203698  5.066667  ...    5.666667   1.236694      2.222222   \n",
       "956   1.966384  4.333333  ...    4.866667   0.516398      2.666667   \n",
       "957   1.024153  5.133333  ...    3.333333   0.899735      3.666667   \n",
       "958   1.181336  5.466667  ...    4.750000   1.064581      2.687500   \n",
       "\n",
       "     W_arous_std  W_familiarity_mean  W_familiarity_std  W_concreteness_mean  \\\n",
       "0       1.909727                 NaN                NaN                  NaN   \n",
       "1       1.586401                 NaN                NaN                  NaN   \n",
       "2       1.909727                 NaN                NaN                  NaN   \n",
       "3       2.600277                 NaN                NaN                  NaN   \n",
       "4       3.214550                 NaN                NaN                  NaN   \n",
       "..           ...                 ...                ...                  ...   \n",
       "954     1.204159                 NaN                NaN                  NaN   \n",
       "955     1.986885                 NaN                NaN                  NaN   \n",
       "956     2.023669                 NaN                NaN                  NaN   \n",
       "957     1.496026                 NaN                NaN                  NaN   \n",
       "958     1.778342                 NaN                NaN                  NaN   \n",
       "\n",
       "     W_concreteness_std  Use-Plaus(0:False/1:True)  \\\n",
       "0                   NaN                        1.0   \n",
       "1                   NaN                        1.0   \n",
       "2                   NaN                        0.0   \n",
       "3                   NaN                        1.0   \n",
       "4                   NaN                        1.0   \n",
       "..                  ...                        ...   \n",
       "954                 NaN                        NaN   \n",
       "955                 NaN                        NaN   \n",
       "956                 NaN                        NaN   \n",
       "957                 NaN                        NaN   \n",
       "958                 NaN                        NaN   \n",
       "\n",
       "     Use-S_valence(0:False/1:True)  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  \n",
       "..                             ...  \n",
       "954                            NaN  \n",
       "955                            NaN  \n",
       "956                            NaN  \n",
       "957                            NaN  \n",
       "958                            NaN  \n",
       "\n",
       "[959 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.chdir('/mnt/c/Users/amand/Downloads/ratings_072323')\n",
    "df1 = pd.read_excel('master_sheet_v3-1(2023.07.19_1st_round)_updated.xlsx', sheet_name='master_sheet').tail(479)\n",
    "df2 = pd.read_excel('master_sheet_v3-2(2023.07.19_2nd_round).xlsx', sheet_name='master_sheet')\n",
    "\n",
    "from IPython.display import display\n",
    "display(df1)\n",
    "display(df2)\n",
    "\n",
    "df = pd.concat((df1, df2)).reset_index(drop=True)\n",
    "df = df.reindex(REINDEX(df['Index'])).reset_index(drop=True)\n",
    "display(df)\n",
    "df.to_excel('/home/amandalin047/july_ratings/results/all_master_sheet.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e722158d-16b1-4cb1-9ab8-f0ee23b5368d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = df['Index'].tolist()\n",
    "[i for i in idx if idx.count(i)!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb29770-8f01-4a77-810b-968ffa0fb029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(df1, df2, exp_thresh=4.5, plaus_thresh=5, val_thresh=2, condition=None, disp=True, drop=True):\n",
    "    df = pd.concat((df1, df2)).reset_index(drop=True);\n",
    "    df = df.reindex(REINDEX(df['cloze(unexp_uncorrected)'])).reset_index(drop=True);\n",
    "    \n",
    "    num_zero_cloze = len([i for i in df['cloze(unexp_uncorrected)'].tolist() if i==0])\n",
    "    new_df = pd.DataFrame(None, columns=df.columns)\n",
    "    for i in range(len(df.head(num_zero_cloze))):\n",
    "        if df['exp_mean'].iloc[i] <= exp_thresh: new_df.loc[len(new_df)] = df.iloc[i]     \n",
    "\n",
    "    for i in range(len(df.head(num_zero_cloze)),len(df)):\n",
    "        if df['Index'].iloc[i] in new_df['Index'].tolist(): new_df.loc[len(new_df)] = df.iloc[i]\n",
    "    \n",
    "    new_df = new_df.reindex(REINDEX(new_df['Index'])).reset_index(drop=True)\n",
    "    \n",
    "    new_df = new_df[new_df['plaus_mean']>=plaus_thresh]\n",
    "    if condition == 'Emo':\n",
    "        new_df = new_df[(new_df['S_val_mean']>=5+val_thresh) | (new_df['S_val_mean']<=5-val_thresh)].reset_index(drop=True)\n",
    "    # need to change the <5+val_thresh to <=5+val_thresh and >5-val_thresh to >=5-val_thresh\n",
    "    # during the next round of more strict stimuli selection\n",
    "    # deleted the equal sign to include all sentences, otherwise there'd be overlap at abs(S_val-5)=1 between Neu and Emo\n",
    "    elif condition == 'Neu':\n",
    "        new_df = new_df[(new_df['S_val_mean']<5+val_thresh) & (new_df['S_val_mean']>5-val_thresh)].reset_index(drop=True)\n",
    "    new_df = new_df.reindex(REINDEX(new_df['Index'])).reset_index(drop=True)\n",
    "    \n",
    "    # drops sentences that do not have a counterpart\n",
    "    if drop == True:\n",
    "        idx = new_df['Index'].tolist()\n",
    "        for i, x in enumerate(idx):\n",
    "            if idx.count(x) == 1:\n",
    "                new_df = new_df.drop(index=i)\n",
    "                \n",
    "    if drop == True:\n",
    "        sc, wc = new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)], new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)]\n",
    "        print('number of '+condition+'_SC frames (i.e., with counterparts) =', int(len(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)])/2))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)])\n",
    "        print('number of '+condition+'_WC frames (i.e., with counterparts) =', int(len(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)])/2))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)])\n",
    "    else:\n",
    "        sc, wc = new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)], new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)]\n",
    "        print('number of '+condition+'_SC sentences =', len(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)]))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==0) | (new_df['Index']%4==1)])\n",
    "        print('number of '+condition+'_WC sentences =', len(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)]))\n",
    "        if disp == True: display(new_df[(new_df['Index']%4==2) | (new_df['Index']%4==3)])  \n",
    "    \n",
    "    return sc, wc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6bdcf-0933-41aa-a1a3-5bb035666cf8",
   "metadata": {},
   "source": [
    "## Stimuli Selection to be Rated for Familiarity & Concreteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b3f13a-7fb6-4eb0-8b81-353614825c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Emo_SC frames (i.e., with counterparts) = 128\n",
      "number of Emo_WC frames (i.e., with counterparts) = 122\n",
      "number of Neu_SC frames (i.e., with counterparts) = 84\n",
      "number of Neu_WC frames (i.e., with counterparts) = 78\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/mnt/c/Users/amand/Downloads/ratings_072323')\n",
    "df1 = pd.read_excel('master_sheet_v3-1(2023.07.19_1st_round)_updated.xlsx', sheet_name='master_sheet').tail(487)\n",
    "df2 = pd.read_excel('master_sheet_v3-2(2023.07.19_2nd_round).xlsx', sheet_name='master_sheet')\n",
    "\n",
    "emo_sc, emo_wc = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=1, condition='Emo', disp=False, drop=True);\n",
    "neu_sc, neu_wc = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=1, condition='Neu', disp=False, drop=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7946c7c-3f52-436a-a1ac-98aa52deec3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Emo_SC sentences = 274\n",
      "number of Emo_WC sentences = 271\n",
      "number of Neu_SC sentences = 178\n",
      "number of Neu_WC sentences = 167\n",
      "\n",
      "\n",
      "number of singled out Emo_SC sentences (i.e., with no counterpart) = 18\n",
      "number of singled out Emo_WC sentences (i.e., with no counterpart) = 27\n",
      "number of singled out Neu_SC sentences (i.e., with no counterpart) = 10\n",
      "number of singled out Neu_WC sentences (i.e., with no counterpart) = 11\n"
     ]
    }
   ],
   "source": [
    "emo_sc_toSubset, emo_wc_toSubset = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=1, condition='Emo', disp=False, drop=False);\n",
    "neu_sc_toSubset, neu_wc_toSubset = main(df1, df2, exp_thresh=8, plaus_thresh=3.7, val_thresh=1, condition='Neu', disp=False, drop=False);\n",
    "\n",
    "toSubset = [emo_sc_toSubset, emo_wc_toSubset, neu_sc_toSubset, neu_wc_toSubset]\n",
    "subsetted = []\n",
    "for f in toSubset:\n",
    "    new_df = pd.DataFrame(None, columns=f.columns)\n",
    "    idx = f['Index'].tolist()\n",
    "    for i, x in enumerate(idx):\n",
    "        if idx.count(x) == 1: new_df.loc[len(new_df)] = f.iloc[i]\n",
    "    subsetted.append(new_df)\n",
    "print('\\n')    \n",
    "to_print = ['number of singled out Emo_SC sentences (i.e., with no counterpart) = ', 'number of singled out Emo_WC sentences (i.e., with no counterpart) = ',\n",
    "            'number of singled out Neu_SC sentences (i.e., with no counterpart) = ', 'number of singled out Neu_WC sentences (i.e., with no counterpart) = ']\n",
    "for i, x in enumerate(subsetted):\n",
    "    print(to_print[i] + str(len(x.index)))\n",
    "    \n",
    "disp, to_excel = False, False\n",
    "if disp == True: dsipaly(x)\n",
    "if to_excel == True: x.to_excel('/home/amandalin047/july_ratings/'+to_print[i]+'.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4daf4bb9-4053-44d5-9aa0-aa1d84fca35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving data frames as separate sheets in one single Excel file (finally figued out how lol)\n",
    "to_write = [emo_sc, emo_wc, neu_sc, neu_wc]\n",
    "    \n",
    "to_write_all = to_write[0]\n",
    "for w in to_write[1:]:\n",
    "    to_write_all = pd.concat((to_write_all, w)).reset_index(drop=True)\n",
    "to_write_all = to_write_all.reindex(REINDEX(to_write_all['Index'])).reset_index(drop=True)\n",
    "to_write.append(to_write_all)\n",
    "    \n",
    "sheet_names = ['Emo_SC', 'Emo_WC', 'Neu_SC', 'Neu_WC', 'All']                                                                     \n",
    "\n",
    "with pd.ExcelWriter('/mnt/c/Users/amand/Downloads/selected_stimuli.xlsx') as writer:\n",
    "    for i,w in enumerate(to_write): w.to_excel(writer, sheet_name=sheet_names[i], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b8bfa2-41d7-4764-86c7-1b57e4880291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_write = subsetted\n",
    "    \n",
    "to_write_all = to_write[0]\n",
    "for w in to_write[1:]:\n",
    "    to_write_all = pd.concat((to_write_all, w)).reset_index(drop=True)\n",
    "to_write_all = to_write_all.reindex(REINDEX(to_write_all['Index'])).reset_index(drop=True)\n",
    "to_write.append(to_write_all)\n",
    "    \n",
    "sheet_names = ['Emo_SC_sing', 'Emo_WC_sing', 'Neu_SC_sing', 'Neu_WC_sing', 'All_sing']                                                                     \n",
    "\n",
    "with pd.ExcelWriter('/mnt/c/Users/amand/Downloads/selected_stimuli_sing.xlsx') as writer:\n",
    "    for i,w in enumerate(to_write): w.to_excel(writer, sheet_name=sheet_names[i], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
